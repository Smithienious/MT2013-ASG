\documentclass[a4paper]{article}

% Global layout
\usepackage{fancyhdr, graphicx, hyperref, indentfirst, lastpage, setspace}
\usepackage[margin=40mm]{geometry}

% Encoding
\usepackage[utf8]{vntex, inputenc} % vntex first to avoid Vietnamese auto captions
\usepackage{amsmath, amssymb, gensymb}

% Better table
\usepackage{array, booktabs, multicol, multirow, siunitx}

% Code space
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{minted} % needs --shell-escape flag and Pygments

% Extra
\usepackage{caption, float}

% Page setup
% \allowdisplaybreaks{} % to have page breaks inside align* environment
\hypersetup{urlcolor=blue,linkcolor=black,citecolor=red,colorlinks=true}
\usemintedstyle{emacs}
\numberwithin{equation}{section}
\renewcommand{\arraystretch}{1.2} % space between table rows

% Global style setup
\makeatletter % change font size for not having underfull hbox
\renewcommand\Huge{\@setfontsize\Huge{22pt}{18}}
\makeatother

\AtBeginDocument{\renewcommand*\contentsname{Contents}}
\AtBeginDocument{\renewcommand*\refname{References}}
\setlength{\headheight}{40pt}
\pagestyle{fancy}
\fancyhead{} % clear all header fields
\fancyhead[L]{
  \begin{tabular}{rl}
    \begin{picture}(25,15)(0,0)
    \put(0,-8){\includegraphics[width=8mm, height=8mm]{hcmut.png}}
    \end{picture}
    \begin{tabular}{l}
      \textbf{\bf \ttfamily University of Technology, Ho Chi Minh City}\\
      \textbf{\bf \ttfamily Faculty of Applied Science}
    \end{tabular}
  \end{tabular}
}
\fancyhead[R]{
	\begin{tabular}{l}
		\tiny \bf \\
		\tiny \bf
	\end{tabular}  }
\fancyfoot{} % clear all footer fields
\fancyfoot[L]{\scriptsize \ttfamily Assignment for Probability and Statistics-Academic year 2020 --- 2021}
\fancyfoot[R]{\scriptsize \ttfamily Page {\thepage}/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0.3pt}
\renewcommand{\footrulewidth}{0.3pt}

\everymath{\color{blue}}

\begin{document}

\begin{titlepage}
  \begin{center}
    VIETNAM NATIONAL UNIVERSITY, HO CHI MINH CITY \\
    UNIVERSITY OF TECHNOLOGY \\
    FACULTY OF APPLIED SCIENCE
  \end{center}

  \vspace{1cm}

  \begin{figure}[h!]
    \begin{center}
      \includegraphics[width=3cm]{hcmut.png}
    \end{center}
  \end{figure}

  \vspace{1cm}

  \begin{center}
    \begin{tabular}{c}
      \textbf{\Large Probability and Statistics (MT2013)} \\
      {}                                                  \\
      \midrule                                            \\
      \textbf{\Large Semester 202, Duration: 03 weeks}    \\
      {}                                                  \\
      \textbf{\Huge Assignment}                           \\
      {}                                                  \\
      \bottomrule
    \end{tabular}
  \end{center}

  \vspace{3cm}

  \begin{table}[h]
    \begin{tabular}{rrl}
      \hspace{5cm} & Advisor: & Nguyễn Tiến Dũng \\
    \end{tabular}
  \end{table}

  \begin{center}
    {\footnotesize HO CHI MINH CITY, MAY 2021}
  \end{center}
\end{titlepage}


%\thispagestyle{empty}

\newpage
\tableofcontents
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Member list \& Workload}
\begin{center}
  \begin{tabular}{llclc}
    \toprule
    \textbf{No.} & \textbf{Full name}    & \textbf{Student ID} & \textbf{Problems} & \textbf{Percentage of work} \\
    \midrule
    1            & Lưu Nguyễn Hoàng Minh & 1952845             & Project 2         & 100\%                       \\
    2            & Nguyễn Hoàng          & 1952255             & Project 1         & 100\%                       \\
    3            & Nguyễn Chính Khôi     & 1952793             & Project 1         & 100\%                       \\
    4            & Nguyễn Duy Thành      & 1952456             & Project 1         & 100\%                       \\
    \bottomrule
  \end{tabular}
\end{center}


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Project 1}
\subsection{Problem 1}

Records for the blood lead levels of workers in five buildings of a battery factory are taken as follows:

\begin{center}
  \begin{tabular}{c*{5}S[table-format=1.2]}
    \toprule
    \multirow{2}{*}{Observation} & \multicolumn{5}{c}{Factor level}                                                                                                     \\
    \cmidrule(lr){2-6}
                                 & \multicolumn{1}{c}{F1}           & \multicolumn{1}{c}{F2} & \multicolumn{1}{c}{F3} & \multicolumn{1}{c}{F4} & \multicolumn{1}{c}{F5} \\
    \midrule
    1                            & 0.25                             & 0.22                   & 0.25                   & 0.31                   & 0.22                   \\
    2                            & 0.28                             & 0.25                   & 0.26                   & 0.33                   & 0.28                   \\
    3                            & 0.32                             & 0.24                   & 0.28                   & 0.30                   & 0.28                   \\
    4                            & 0.22                             & 0.28                   & 0.25                   & 0.29                   & 0.25                   \\
    5                            & 0.22                             & 0.31                   & 0.22                   & 0.25                   & 0.30                   \\
    6                            &                                  & 0.21                   & 0.28                   &                        &                        \\
    7                            &                                  & 0.22                   & 0.31                   &                        &                        \\
    \bottomrule
  \end{tabular}
\end{center}

We are to compare the blood lead levels among the workers in the above factory at the significance level \( \alpha = 3\% \).

\subsubsection{Classification}
This problem is classified as Testing for statistical differences among two or more means.

\subsubsection{Method for solving}
Up to this point, we have been comparing two populations using the Independent samples t-test and Matched-sample t-test.
However, they are only so good at testing two samples, but what about more than two samples?
Using multiple t-tests is possible, but the amount of calculation increases rapidly and the type II error rate would compound with each iteration.
A new method was created to issue this problem.
Enter \textbf{Analysis of Variance}.

\subsubsection{Theory base}\label{anovaDef}
Analysis Of Variance (frequently abbreviated ANOVA) was created to aid in comparing means when there are more than two levels of a single factor.

In these kinds of problems, we are asked to compare some values. Let the example hypotheses be:
\begin{align*}
   & H_0: \mu_1 = \mu_2 = \mu_3                  \\
   & H_1: \mu_1 = \mu_2 = \mu_3 \text{ is false}
\end{align*}
which is another way of expressing that these 3 means come from the same overall population.

Obviously the means cannot be exactly equal to the overall mean, but rather we want to know if each mean likely came from a larger overall population.
In ANOVA, this idea is known as the Variability between the sample means.
Each sample mean is a certain distance from the mean of the overall population, which is an expression of variance.
ANOVA also requires Variability within the distributions, which is pretty self-explanatory.

ANOVA is really a variability ratio:
\begin{align*}
  \frac{Variance\ Between}{Variance\ Within}
\end{align*}

If the Variability between the means (distance from overall mean) in the numerator is relatively large compared to the Variability within the samples (internal spread) in the denominator, this ratio will be much larger than 1, meaning that at least one mean is an outlier and each distribution is narrow, distinct from each other.

In the case that the Between variances and the Within variances are similar, means are fairly close to the overall mean or the distributions may overlap.

The other case is where the Between variances is small and the Within variances is very large.
We can think of this like 3 distributions that are very spread out internally and do not have a lot of distance from each other.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{anova.jpg}
\end{figure}

ANOVA really is f-distribution at its core.
For the times when we need to use ANOVA on one factor, we use One-way ANOVA, which defines the F value as follows:
\begin{align*}
  F = \frac{MSF}{MSE}
\end{align*}
with \(MSF\) is the Factor mean square and \(MSE\) is the Error mean square.

We will further expand \(MSF\) and \(MSE\) into these components:
\begin{align*}
  df_{factors} & = F - 1 & MSF & = \frac{SSF}{df_{factors}} \\
  df_{error}   & = N - F & MSE & = \frac{SSE}{df_{error}}   \\
  df_{total}   & = N - 1 & SST & = SSF + SSE
\end{align*}
where \(df = \text{degree of freedom}\), \(N = \text{total observations}\) and \(F = \text{number of factors}\).

Here we define some syntactic sugar. Let \(y_{i\cdot}\) represent the total of the observations under factor \(i\) and \(\bar{y_{i\cdot}}\) represent the average of the observations under factor \(i\).
Similarly, let \(y_{\cdot\cdot}\) represent the grand total of all observations and \(\bar{y_{\cdot\cdot}}\) represent the grand mean of all observations.

For example:
\begin{align*}
  y_{i\cdot}     & = \sum_{j}^{n} y_{ij}                  & \bar{y_{i\cdot}}     & = \frac{y_{i\cdot}}{n}              \\
  y_{\cdot\cdot} & = \sum_{i=1}^{a} \sum_{j=1}^{n} y_{ij} & \bar{y_{\cdot\cdot}} & = \frac{y_{\cdot\cdot}}{a \times n}
\end{align*}

We now have \(SSF\) is the Factor sum of squares, \(SSE\) is the Error sum of squares and \(SST\) is the Total sum of squares
\begin{align*}
   & SST = \sum_{i=1}^{C} \sum_{j=1}^{n_i} y_{ij}^2 - \frac{y_{\cdot\cdot}^2}{N}  \\
   & SSC = \sum_{i=1}^{C} \frac{y_{i\cdot}^{2}}{n_i} - \frac{y_{\cdot\cdot}^2}{N} \\
   & SSE = SST - SSC
\end{align*}
where \(n_i\) is the number of observations taken under treatment \(i\), i.e. \(N = \sum_{i=1}^{C} n_i\).

\subsubsection{Analyze the data with R}
We are comparing the blood lead levels, thus we want the null hypothesis to conclude that there is no difference in means.
\begin{align*}
   & H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5                   \\
   & H_1: \text{Exist a mean that is not equal to the remainings}
\end{align*}

We will be solving this problem step by step with the aid of \(R\).
Firstly, we prepare the data.
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Import the data
data_file <- read.csv(file="ex1.csv")

# Extract group names to data frame
fr_gr_names <- data.frame(unique(data_file$group))

# Variables that aid calculations
fr_gr_sums <- aggregate(data_file$value~data_file$group,
                        fr_gr_names, sum)
fr_gr_quans <- aggregate(data_file$value~data_file$group,
                          fr_gr_names, length)
gr_sums <- fr_gr_sums$`data_file$value`
gr_quans <- fr_gr_quans$`data_file$value`
  \end{minted}
\end{mdframed}

We begin with the component variables, then slowly make our way to F value.
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Degree of freedom
N <- length(data_file$value)
F <- length(unique(data_file$group))
df_f <- F - 1
df_e <- N - F
df_t <- N - 1

# Sums of squares
SST <- sum(data_file$value^2) - sum(data_file$value)^2 / N
SSF <- sum(gr_sums^2 / gr_quans) - sum(data_file$value)^2 / N
SSE <- SST - SSF

# Means of sums of squares
MSF <- SSF / df_f
MSE <- SSE / df_e

F <- MSF / MSE
  \end{minted}
\end{mdframed}

We now use some unicorn magic to obtain the output
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Console output
cat("Sums", gr_sums, "\n")
cat("Averages", gr_sums / gr_quans, "\n")
cat("Overall sum", sum(gr_sums), "\n")
cat("Overall mean", mean(gr_sums / gr_quans), "\n")
cat("df_f", df_f, "\n")
cat("df_e", df_e, "\n")
cat("df_t", df_t, "\n")
cat("SSF", SSF, "\n")
cat("SSE", SSE, "\n")
cat("SST", SST, "\n")
cat("MSF", MSF, "\n")
cat("MSE", MSE, "\n")
cat("F", F, "\n")
  \end{minted}
\end{mdframed}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
Sums 1.29 1.73 1.85 1.48 1.33
Averages 0.258 0.2471429 0.2642857 0.296 0.266
Overall sum 7.68
Overall mean 0.2662857
df_f 4
df_e 24
df_t 28
SSF 0.007289852
SSE 0.02763429
SST 0.03492414
MSF 0.001822463
MSE 0.001151429
F 1.582784
  \end{minted}
\end{mdframed}

Let's arrange this mess into a table for some reason.
\begin{center}
  \begin{tabular}{cccccccccc}
    \toprule
    Factor level & \multicolumn{7}{c}{Observation} & Sum  & Average                                                \\
    \midrule
    F1           & 0.25                            & 0.28 & 0.32    & 0.22 & 0.22 &      &      & 1.29 & 0.258     \\
    F2           & 0.22                            & 0.25 & 0.24    & 0.28 & 0.31 & 0.21 & 0.22 & 1.73 & 0.2471429 \\
    F3           & 0.25                            & 0.26 & 0.28    & 0.25 & 0.22 & 0.28 & 0.31 & 1.85 & 0.2642857 \\
    F4           & 0.31                            & 0.33 & 0.30    & 0.29 & 0.25 &      &      & 1.47 & 0.296     \\
    F5           & 0.22                            & 0.28 & 0.28    & 0.25 & 0.30 &      &      & 1.33 & 0.266     \\
    \bottomrule
  \end{tabular}
\end{center}
\begin{center}
  \begin{tabular}{lcccc}
    \toprule
    Source of variation & Df & Sum of squares & Mean square & F        \\
    \midrule
    Factor level        & 4  & 0.007289852    & 0.001822463 &          \\
    Error               & 24 & 0.02763429     & 0.001151429 &          \\
    Total               & 28 & 0.03492414     &             & 1.582784 \\
    \bottomrule
  \end{tabular}
\end{center}

Congratulations! We have calculated the F value of this problem \(F = 1.582784\).
Moreover, the same results can be obtained using the built in One-way ANOVA function.
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Import the data
data_file <- read.csv(file="resources/ex1.csv")

# Built-in one-way ANOVA
av = aov(data_file$value~data_file$group)

# Results
print(summary(av))
  \end{minted}
\end{mdframed}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
                Df  Sum Sq  Mean Sq F value Pr(>F)
data_file$group  4 0.00729 0.001822   1.583  0.211
Residuals       24 0.02763 0.001151
  \end{minted}
\end{mdframed}

\subsubsection{Conclusion}
The statistical appendix doesn't have an entry for \(f(0.03, 4, 24)\), thus we called for some help from \(R\).
Due to the way it is implemented, we use \(qf(0.97, 4, 24)\) but not \(qf(0.03, 4, 24)\).
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
> cat("F Crit", qf(0.97,4,24), "\n")
  \end{minted}
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
F Crit 3.21831
  \end{minted}
\end{mdframed}

Because \(F < F crit\), i.e. \(1.582784 < 3.21831\), we fail to reject the null hypothesis.
In other words, the blood samples are statistically the same.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 2}\label{p2}
Data of skilled workers who are Swedish between two age groups dated back in 1930 are shown in the following table:

\begin{center}
  \begin{tabular}{ccccccc}
    \toprule
    \multirow{2}{*}{Age group} & \multicolumn{6}{c}{Income levels}                                   \\
    \cmidrule(lr){2-7}
                               & 0--1                              & 1--2 & 2--3 & 3--4 & 4--6 & >6  \\
    \midrule
    40--50                     & 71                                & 430  & 1072 & 1609 & 1178 & 158 \\
    50--60                     & 54                                & 324  & 894  & 1202 & 903  & 112 \\
    \bottomrule
  \end{tabular}
\end{center}

The required work is to verify if these two age groups are indistinguishable or not with the significance level \( \alpha = 5\% \).

\subsubsection{Classification}
The problem is classified as Testing for dependency of categorical variables.

\subsubsection{Method for solving}
By far, we have encountered many hypothesis testing methods such as testing for the mean to make sense in a given sample whether it is different, lesser or greater than the sample mean. But now we are facing a problem which involves showing the difference between groups in a given sample, none of the fore-mentioned are valid to apply. So we will approach this problem via a method called \textbf{Chi-Square test for independence}.

\subsubsection{Theory base}\label{p2:theory}
The Chi-Square test is a statistical procedure used by researchers to examine the differences between categorical variables in the same population. First we construct a null hypothesis which states that the categories in the sample are no different, and the alternative hypothesis which is the complement of that null hypothesis.
\begin{align*}
   & H_0: \text{Groups in the data sample are independent} \\
   & H_1: \text{Groups in the data sample are dependent}
\end{align*}

We then calculate the Chi-Square statistic:
\begin{align*}
  \chi_0^2 = \sum_{i = 1}^{k} \frac{{(O_i - E_i)}^2}{E_i}
\end{align*}\label{chi:stat}

Where \(O_i\) and \(E_i\) is the observed frequency and the expected frequency of the \(i^{th}\) category respectively.

After obtaining the statistic we can compare to \(c\), the critical point of Chi-Square distribution. If it is bigger then we reject the null hypothesis, if it is not then we accept the hypothesis.

An alternative method is to calculate the \(\text{p-value}\) of the sample and compare it to the significance level \( \alpha \). This is similar to other hypothesis testing method, of which the p-value does not exceed the significance level then we reject the null hypothesis and vice versa.

\subsubsection{Analyze the data using R}\label{p2:anal}
Considering a null hypothesis with the alternative hypothesis:
\begin{align*}
   & H_0 : \text{The two groups have no relationship towards each other} \\
   & H_1 : \text{There exists connection between these two groups}
\end{align*}

Using \(R\), we can apply Chi-Square test to the data sample. First, we import the data located in the \(resources\) folder, using the following simple commands:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Import the data
file_path <- 'resources/ex2.csv'
income <- read.csv(file = file_path, sep = ",", row.names = 1, stringsAsFactors = FALSE, check.names = FALSE)
data <- as.matrix(income)
  \end{minted}
\end{mdframed}

After that, we compute the Chi-Square test using built-in functions. Then we can visualize the data for verification and further demonstration:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Computing Chi-square
chisq <- chisq.test(data)

# Print observed counts & expected counts
print(chisq$observed)
print(round(chisq$expected, 2))
print(chisq)
  \end{minted}
\end{mdframed}

The output should be:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
> print(chisq$observed)
      0-1 1-2  2-3  3-4  4-6  >6
40-50  71 430 1072 1609 1178 158
50-60  54 324  894 1202  903 112
> print(round(chisq$expected, 2))
        0-1    1-2     2-3     3-4     4-6     >6
40-50 70.53 425.45 1109.33 1586.12 1174.22 152.35
50-60 54.47 328.55  856.67 1224.88  906.78 117.65
> print(chisq)

	Pearson's Chi-squared test

data:  data
X-squared = 4.2675, df = 5, p-value = 0.5116
  \end{minted}
\end{mdframed}

To calculate the Chi-Square statistic, first we construct an expected frequency table based on the observed data through this formula:
\begin{align*}
  O_{ij} = \frac{SR_i * SC_j}{ST}
\end{align*}

Where \(SR_i\) is the sum of \(i^{th}\) row, \(SC_j\) is the sum of \(j^{th}\) column and \(ST\) is the total sum of the observation. The expected frequency table:
\begin{center}
  \begin{tabular}{ccccccc}
    \toprule
    \multirow{2}{*}{Age group} & \multicolumn{6}{c}{Income levels --- Expected frequency}                                                          \\
    \cmidrule(lr){2-7}
                               & 0--1                                                     & 1--2     & 2--3      & 3--4     & 4--6      & >6       \\
    \midrule
    40--50                     & 70.5320                                                  & 425.4492 & 1109.3278 & 1586.124 & 1174.2173 & 152.3492 \\
    50--60                     & 54.468                                                   & 328.5508 & 856.6722  & 1224.876 & 906.7827  & 117.6508 \\
    \bottomrule
  \end{tabular}
\end{center}

Afterwards we use \hyperref[chi:stat]{\underline{this formula}} to calculate the statistic, we will get a value of \( \chi_0^2 = 4.2675\). Compare this to the value \( X-squared \) printed in the result, we can see it is identically the same.

The following step is to store value from the computed Chi-Square and calculate new required variables:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Retrieving value
alpha = 0.05
X_squared = chisq$statistic # Statistic
df = chisq$parameter        # Degree of freedom
pval = chisq$p.value        # P-value
c = qchisq(1 - alpha, df)    # Computing critical point
  \end{minted}
\end{mdframed}

Finally, we compare the values to draw a conclusion which is to reject the null hypothesis or not:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Check for rejection by comparing with critical point
ifelse(
  X_squared > c,
  "Reject H0 by comparing with critical point",
  "Accept H0 by comparing with critical point"
)

#Check for rejection by comparing with significance level
ifelse(
  pval < alpha,
  "Reject H0 by comparing with significance level",
  "Accept H0 by comparing with significance level"
)
  \end{minted}
\end{mdframed}

If we look closely, we can see that there are two \(ifelse\) statements. These represent the two methods to come to a conclusion that the null hypothesis is rejected or not. The output should be:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
"Accept H0 by comparing with critical point"
[1] "Accept H0 by comparing with significance level"
  \end{minted}
\end{mdframed}

\subsubsection{Conclusion}
Observing the result above, both method yield the result which accepts null hypothesis, which means \(\chi_0^2 < \chi_{\alpha, v}^2\) and \(\text{p-value} > \alpha \) so we accept the null hypothesis \(H_0\).

\textbf{In conclusion, the two age groups have identical income with the scale of income levels.}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 3}

This table below views the number of late arrivals in four high schools on different days.

\begin{center}
  \begin{tabular}{cccccc}
    \toprule
    \multirow{2}{*}{Days of week} & \multicolumn{4}{c}{High School}             \\
    \cmidrule(lr){2-5}            & A                               & B & C & D \\
    \midrule
    Monday                        & 5                               & 4 & 5 & 7 \\
    Tuesday                       & 4                               & 5 & 3 & 2 \\
    Wednesday                     & 4                               & 3 & 4 & 5 \\
    Thursday                      & 4                               & 4 & 3 & 2 \\
    \bottomrule
  \end{tabular}
\end{center}

We are to determine, at the significance level of \( \alpha = 1\% \), if there is a significant difference in the number of late arrivals among different days of the week.

\subsubsection{Classification}
The problem is classified as a dependency of an independent variable to the dependent variables.

\subsubsection{Method for solving}
For this problem, since there are two factors affecting to the hypothesis we will be using Two-Way ANOVA.\
Also, every block has a definite and assigned random value, we consider this as a Random Complete Block Design (RCDB) and therefore RCBD is used to solve this Two-Way ANOVA problem.

\subsubsection{Theory base}

For definition of Analysis Of Variance (ANOVA) and One-Way ANOVA, refer to \hyperref[anovaDef]{\underline{Theory base of Problem 1}}.

However, One-Way ANOVA solves the problem with only one factor affecting its end result. If there are two factors, One-way ANOVA yields to fail as it only calculates one factor as \(SSC\) while the other factor will be ignored. So although \(SST\) will remain the same, \(SSE\) will be too large due to lack of the second factor, giving false \(F0\) and thus false conclusion.

Two-Way ANOVA solves the trivial problem as it uses a categorical variable --- or blocks --- to calculate the missing second factor. This means a third element, called \(SSB\), is added when formulating \(SST\),  calculates the sum of squares of blocks:

\begin{align*}
  SSB = \frac{1}{a}.\sum_{j=1}^{b}(y^2_{.j} - \frac{y^2_{..}}{ab})
\end{align*}

With \(a = \text{number of columns}\) and \(b = \text{number of blocks}\).

Therefore, the formula of sum of squares \(SST\) in a Two-Way ANOVA is:

\begin{align*}
  SST = SSC + SSB + SSE
\end{align*}

And since \(SST\) and \(SSC\) does not change, \(SSE\) can be calculated as in One-Way ANOVA with implementation of \(SSB\).

\begin{align*}
  SST = \sum_{i=1}^{a}\sum_{j=1}^{b}(y^2_{ij} - \frac{y^2_{..}}{ab}) \\
  SSC = \frac{1}{b}.\sum_{i=1}^{a}(y^2_{i.} - \frac{y^2_{..}}{ab})   \\
  SSE = SST - SSC - SSB
\end{align*}

Now that we have successfully recalculate \(SSE\) with implementation of the second factor, we can calculate \(\text{degree of free dom df}\) and \(\text{mean of sum of  squares MS}\) like in One-Way ANOVA.\

\begin{align*}
  df_{columns} & = a - 1      & MSC & = \frac{SSC}{df_{columns}} \\
  df_{blocks}  & = b - 1      & MSB & = \frac{SSb}{df_{blocks}}  \\
  df_{error}   & = (a-1)(b-1) & MSE & = \frac{SSE}{df_{error}}   \\
  df_{total}   & = N-1
\end{align*}

where  \(a = \text{number of columns}\) and \(b = \text{number of blocks}\).

And eventually calculate our final result for hypothesis testing

\begin{align*}
  F = \frac{MSC}{MSE}
\end{align*}
\subsubsection{Analyze the data using R}

As we are comparing differences between of days in the week, we assume the null hypothesis that there is no difference.

\begin{align*}
  H_0: \mu_1. = \mu_2. = \mu_3. = \mu_4. \\
  H_1: \exists\mu_i. \neq 0
\end{align*}

The next step is to determine the number of columns and blocks as well as significant level of the hypothesis based on the given data.

\begin{center}
  \begin{tabular}{lcccccc}
    \toprule
    Days of week & \multicolumn{4}{c}{High School} & Sum & Average                  \\
    \cmidrule(lr){2-5}
                 & A                               & B   & C       & D              \\
    \midrule
    Monday       & 5                               & 4   & 5       & 7  & 21 & 5.25 \\
    Tuesday      & 4                               & 5   & 3       & 2  & 14 & 3.5  \\
    Wednesday    & 4                               & 3   & 4       & 5  & 16 & 4    \\
    Thursday     & 4                               & 4   & 3       & 2  & 13 & 3.25 \\
    \midrule
    Sum          & 17                              & 16  & 15      & 16             \\
    Average      & 4.25                            & 4   & 3.75    & 4              \\
    \bottomrule
  \end{tabular}
\end{center}

From this point onwards, R can help us with the calculation.

Firstly, we prepare the data
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
  #Import the data
Ques3_dataset <- read.csv(file = "resources/ex3.csv")
head(Ques3_dataset)
    \end{minted}
\end{mdframed}

Then, applying Two-way ANOVA using the built-in function

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
#Create a two-way ANOVA
av <- aov(value ~ day_of_week + highschool,data=Ques3_dataset)
    \end{minted}
\end{mdframed}

Printing the data of to the console

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
#Summarize two-way ANOVA
print(summary(av))
    \end{minted}
\end{mdframed}

Checking the critical value. Note that we are working on a 4x4 table with significance level of \(\alpha = 1\%\). Therefore \(a = b = 3, \alpha = 0.01\)

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
  #Check critical value
  print(qf(0.99,3,9)
    \end{minted}
\end{mdframed}

And finally check if we can reject the null hypothesis or not
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
#Check and output if we can reject h0 or not
ifelse(
  summary(av)[[1]][["Pr(>F)"]] > qf(0.99,3,9),
  print("Reject H0 since F >", qf(0.99,3,9)),
  print("Fail to reject H0 since F <", qf(0.99,3,9))
)
  \end{minted}
\end{mdframed}

Outputs:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
            Df Sum Sq Mean Sq F value Pr(>F)
day_of_week  3    9.5   3.167   2.036  0.179
highschool   3    0.5   0.167   0.107  0.954
Residuals    9   14.0   1.556
[1] "6.991917"
[1] "Fail to reject H0 since F < 6.991917"
  \end{minted}
\end{mdframed}

\subsubsection{Conclusion}
From the output of the program, we have 2 F values, since we only work on different days of week, the first Fvalue will be our subject of comparison. And from the output of the program, we conclude that \(2.036 < 6.991917\), we fail to reject \(H_0\)

\textbf{In other words, there is no difference in the number of late arrvals among different days of the week.}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 4}
The thickness of nickel coating has been scientifically tested, the measurement in different plating tanks obtained from the experiment is described in the following data:
\begin{center}
  \begin{tabular}{cccc}
    \toprule
    \multirow{2}{*}{Thickness of nickel coating} & \multicolumn{3}{c}{Plating tank}            \\
    \cmidrule(lr){2-4}
                                                 & A                                & B   & C  \\
    \midrule
    4--8                                         & 32                               & 51  & 68 \\
    8--12                                        & 123                              & 108 & 80 \\
    12--16                                       & 10                               & 26  & 26 \\
    16--20                                       & 41                               & 24  & 28 \\
    20--24                                       & 19                               & 20  & 28 \\
    \bottomrule
  \end{tabular}
\end{center}

With significance level \( \alpha = 5\% \), ``For every plating tank, we can have a relatively identical result of the coating thickness'' is the hypothesis that needs tested.

\subsubsection{Classification}
The problem is classified as Testing for dependency of categorical variables.

\subsubsection{Method for solving}
The problem requires us to test for the hypothesis which states that there exists no dependency between categories. This is similar to the fore-mentioned \hyperref[p2]{\underline{Problem 2}} so we will use \textbf{Chi-Square test for independence}.

\subsubsection{Theory base}
The theory of Chi-Square testing for dependency has already been defined in the \hyperref[p2:theory]{\underline{Theory base of Problem 2}}.

\subsubsection{Analyze the data using R}
For this problem, we construct a null hypothesis and the following alternative hypothesis:
\begin{align*}
   & H_0 : \text{The coating thickness and the type of plating tank used are independent} \\
   & H_1 : \text{The type of plating tank is related to the thickness of nickel coating}
\end{align*}

For analyzing the data, we will use \(R\). The first step should be requiring the data from \(resources\) folder:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Import the data
file_path <- 'resources/ex4.csv'
type <- read.csv(file = file_path, sep = ",", row.names = 1, stringsAsFactors = FALSE, check.names = FALSE)
data <- as.matrix(type)
  \end{minted}
\end{mdframed}

Next, with the help of existed packages from \(R\), we use the functions from those to calculate Chi-Square statistic and many others and then visualize the data:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Computing Chi-square
chisq <- chisq.test(data)

# Print observed counts & expected counts
print(chisq$observed)
print(round(chisq$expected, 2))
  \end{minted}
\end{mdframed}

The expected output:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
> print(chisq$observed)
        A   B  C
4-8    32  51 68
8-12  123 108 80
12-16  10  26 26
16-20  41  24 28
20-24  19  20 28
> print(round(chisq$expected, 2))
           A      B      C
4-8    49.67  50.55  50.77
8-12  102.30 104.12 104.58
12-16  20.39  20.76  20.85
16-20  30.59  31.14  31.27
20-24  22.04  22.43  22.53
> print(chisq)

	Pearson's Chi-squared test

data:  data
X-squared = 37.667, df = 8, p-value = 8.674e-06
  \end{minted}
\end{mdframed}

Doing this manually, the expected frequency table after applying the formula mentioned in \hyperref[p2:anal]{\underline{Analyzing stage of Problem 2}} will be:

\begin{center}
  \begin{tabular}{cccc}
    \toprule
    \multirow{2}{*}{Thickness of nickel coating} & \multicolumn{3}{c}{Plating tank}                       \\
    \cmidrule(lr){2-4}
                                                 & A                                & B        & C        \\
    \midrule
    4--8                                         & 49.6711                          & 50.5541  & 50.7749  \\
    8--12                                        & 102.3026                         & 104.1213 & 104.5760 \\
    12--16                                       & 20.3947                          & 20.7573  & 20.8480  \\
    16--20                                       & 30.5921                          & 31.1360  & 31.2719  \\
    20--24                                       & 22.0395                          & 22.4313  & 22.5292  \\
    \bottomrule
  \end{tabular}
\end{center}

Moving on to finding the statistic, using \hyperref[chi:stat]{\underline{this formula}} the value will be \( \chi_0^2 = 37.6670\). The result obtained through analyzing with R and the result here are similar, close to being alike.

The following step includes extracting and calculate further data:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Retrieving value
alpha = 0.05
X_squared = chisq$statistic # Statistic
df = chisq$parameter        # Degree of freedom
pval = chisq$p.value        # P-value
c = qchisq(1 - alpha, df)    # Computing critical point
  \end{minted}
\end{mdframed}

To wrap up the program, we compare the values to come to conclusion:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
# Check for rejection by comparing with critical point
ifelse(
  X_squared > c,
  "Reject H0 by comparing with critical point",
  "Accept H0 by comparing with critical point"
)

#Check for rejection by comparing with significance level
ifelse(
  pval < alpha,
  "Reject H0 by comparing with significance level",
  "Accept H0 by comparing with significance level"
)
  \end{minted}
\end{mdframed}

The result after executing:
\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{text}
"Reject H0 by comparing with critical point"
[1] "Reject H0 by comparing with significance level"
  \end{minted}
\end{mdframed}

\subsubsection{Conclusion}
The output above gives us the result of both method being rejecting the null hypothesis. This means \(\chi_0^2 < \chi_{\alpha, v}^2\) and \(\text{p-value} > \alpha \) are true so we wrap up the problem.

\textbf{To summarize the problem, the hypothesis which states that there are no relationship between thickness of nickel coating and type of plating tank is false}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Project 2}
\subsection{Problem 1}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
    print("Cặc Khôi ngắn!");
  \end{minted}
\end{mdframed}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 2}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
    print("Cặc Khôi ngắn!");
  \end{minted}
\end{mdframed}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 3}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
    print("Cặc Khôi ngắn!");
  \end{minted}
\end{mdframed}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem 4}

\begin{mdframed}[leftline=false,rightline=false,backgroundcolor=magenta!10,nobreak=true]
  \begin{minted}[linenos,breaklines,breaksymbolleft=,obeytabs=true,tabsize=2]{R}
    print("Cặc Khôi ngắn!");
  \end{minted}
\end{mdframed}

\end{document}
